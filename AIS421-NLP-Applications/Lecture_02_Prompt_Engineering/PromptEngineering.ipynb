{
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# AIS421 Lecture 2: Prompt Engineering\n",
"Nile University - Spring 2026\n",
"Instructor: Dr. Ensaf Hussein\n",
"\n",
"\n",
"\n",
"---\n",
"\n",
"## üìë Overview\n",
"Prompt engineering is a discipline focused on developing and optimizing prompts to effectively interact with Large Language Models (LLMs). This lecture covers settings, core techniques, and advanced reasoning frameworks.\n",
"\n",
"## ‚öôÔ∏è Part 1: LLM Settings\n",
"Configurable parameters influence the randomness, length, and diversity of model responses.\n",
"\n",
"| Parameter | Impact | Usage |\n",
"| :--- | :--- | :--- |\n",
"| Temperature | Controls randomness | 0.2 for facts, 0.8 for creativity |\n",
"| Top P | Nucleus Sampling | Range of possible next words |\n",
"| Max Length | Token Limit | Prevents long, irrelevant outputs |\n",
"| Penalties | Repetition Control | Frequency/Presence penalties for variety |"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"!pip install openai\n",
"\n",
"import os\n",
"from openai import OpenAI\n",
"\n",
"client = OpenAI(api_key="") # Set key here\n",
"\n",
"def get_completion(prompt, temp=0.7):\n",
"    response = client.chat.completions.create(\n",
"        model="gpt-4o-mini",\n",
"        messages=[{"role": "user", "content": prompt}],\n",
"        temperature=temp\n",
"    )\n",
"    return response.choices[0].message.content"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## üß† Part 2: Reasoning Techniques\n",
"\n",
"### 1. Chain-of-Thought (CoT)\n",
"Breaking down complex reasoning tasks through intermediary steps.\n",
"\n",
"Slide Example: A juggler can juggle 16 balls. Half of the balls are golf balls, and half of the golf balls are blue. How many blue golf balls are there?"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"logic_problem = "A juggler can juggle 16 balls. Half of the balls are golf balls, and half of the golf balls are blue. How many blue golf balls are there?"\n",
"prompt = f"{logic_problem} Let's think step by step."\n",
"print(get_completion(prompt))"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### 2. Program-Aided Language (PAL)\n",
"Using code execution for intermediate reasoning steps.\n",
"\n",
"Slide Example: Bakery baked 200 loaves, sold 93 in AM, 39 in PM, 6 returned. How many left?"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"pal_prompt = """\n",
"Q: The bakers at the Beverly Hills Bakery baked 200 loaves of bread on Monday morning. \n",
"They sold 93 loaves in the morning and 39 loaves in the afternoon. \n",
"A grocery store returned 6 unsold loaves. How many loaves of bread did they have left?\n",
"A: Write a Python solution.\n",
""""\n",
"print(get_completion(pal_prompt))"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"### 3. ReAct Framework (Reason + Act)\n",
"Interleaving reasoning traces and task-specific actions.\n",
"\n",
"Logic: Thought -> Action -> Observation"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"react_prompt = """\n",
"Question: Aside from the Apple Remote, what other device can control the program Apple Remote was originally designed to interact with?\n",
"Thought: I need to search Apple Remote and find the program it was originally designed to interact with.\n",
"Action: Search[Apple Remote]\n",
"Observation: Originally designed to control the Front Row media center program.\n",
"Thought: Apple Remote was originally designed to control the Front Row media center program. I need to search Front Row next and find what other device can control it.\n",
""""\n",
"print(get_completion(react_prompt))"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## üìù Summary of Advanced Techniques\n",
"- Tree of Thoughts (ToT): Branching paths for complex math (e.g., Game of 24).\n",
"- Meta-Prompting: Structure-oriented prompts emphasizing LaTeX and logic.\n",
"- Generated Knowledge: Creating a knowledge base before answering."
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"name": "python",
"version": "3.10.0"
}
},
"nbformat": 4,
"nbformat_minor": 5
}