{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rG5EQqf4_Tq"
      },
      "source": [
        "# AIS421: Lecture 02: Prompt Engineering\n",
        "## Instructor: Dr. Ensaf Hussein\n",
        "## University: Nile University\n",
        "## Semester: Spring 2026\n",
        "\n",
        "This notebook provides a comprehensive introduction to prompt engineering with hands-on examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4UeT1Ty4_Tu"
      },
      "source": [
        "# Save this notebook as \"prompt_engineering_crash_course.ipynb\"\n",
        "# You can run cells sequentially to learn prompt engineering concepts\n",
        "\n",
        "# Install required packages\n",
        "!pip install openai\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import getpass"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ByYGM2h4_Tv"
      },
      "source": [
        "## Part 1 — Quick Introduction\n",
        "\n",
        "### What is Prompt Engineering?\n",
        "A discipline focused on developing and optimizing prompts to effectively interact with Large Language Models (LLMs). It is a hybrid between programming, instructing, and teaching.\n",
        "\n",
        "### Why It Matters\n",
        "- **Research & Discovery**: Helps test and evaluate the boundaries and limitations of LLMs\n",
        "- **Innovation**: Enables complex applications like autonomous agents and reasoning systems\n",
        "- **Career Path**: Companies like Anthropic now hire \"Prompt Engineers & Librarians\" with competitive salaries ($250k - $335k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcFKH2e04_Tw"
      },
      "source": [
        "## Part 2 — LLM Settings & Configurations\n",
        "\n",
        "Configurable parameters that influence how an LLM generates responses.\n",
        "\n",
        "### 1. Main Definitions\n",
        "\n",
        "**Temperature**: Controls randomness\n",
        "- **Low (e.g., 0.2)**: More predictable, fact-based responses\n",
        "- **High (e.g., 0.8)**: More creative, varied responses\n",
        "\n",
        "**Top P (Nucleus Sampling)**: Determines the range of possible next words\n",
        "- **Low (e.g., 0.1)**: More confident and exact responses\n",
        "- **High (e.g., 0.9)**: More diverse and exploratory\n",
        "\n",
        "> **Tip**: Adjust either Temperature or Top P, but not both.\n",
        "\n",
        "### 2. Output Length & Structure\n",
        "- **Max Length**: Maximum number of tokens (words/subwords) the model can generate\n",
        "- **Stop Sequences**: Specific characters that signal the model to stop\n",
        "  - *Example*: Adding \"11.\" as a stop sequence stops a numbered list at 10 items\n",
        "\n",
        "### 3. Repetition Control\n",
        "- **Frequency Penalty**: Penalizes overused tokens. Higher values result in more varied vocabulary\n",
        "- **Presence Penalty**: Encourages the model to use new words/topics. Higher values result in more diverse wording\n",
        "\n",
        "> **Tip**: Adjust either Frequency or Presence Penalty, but not both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TiX98EG4_Tx"
      },
      "source": [
        "# Setup OpenAI client\n",
        "print(\"Please enter your OpenAI API key:\")\n",
        "api_key = getpass.getpass()\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def get_completion(prompt, temp=0.7, top_p=1.0, max_tokens=256,\n",
        "                   frequency_penalty=0, presence_penalty=0,\n",
        "                   stop_sequences=None):\n",
        "    \"\"\"\n",
        "    A flexible function to get completions from OpenAI with various parameters.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # Using a cost-effective model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temp,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "        presence_penalty=presence_penalty,\n",
        "        stop=stop_sequences\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMJ1U7gB4_Ty"
      },
      "source": [
        "## Part 3 — Your First Prompt (Hands-On)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IglEXxPS4_Tz"
      },
      "source": [
        "# Basic completion example\n",
        "print(\"Example 1: Basic completion with default settings\")\n",
        "result = get_completion(\"The sky is\")\n",
        "print(f\"Prompt: 'The sky is'\\nOutput: '{result}'\\n\")\n",
        "\n",
        "# Compare temperature effects\n",
        "print(\"Example 2: Comparing temperature effects\")\n",
        "print(\"\\nLow temperature (0.2) - More predictable:\")\n",
        "result_low = get_completion(\"Write a one-sentence story about a robot\", temp=0.2)\n",
        "print(result_low)\n",
        "\n",
        "print(\"\\nHigh temperature (0.9) - More creative:\")\n",
        "result_high = get_completion(\"Write a one-sentence story about a robot\", temp=0.9)\n",
        "print(result_high)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KSYUB_F4_T0"
      },
      "source": [
        "## Part 4 — Core Techniques (By Example)\n",
        "\n",
        "### 1. Zero-Shot Prompting\n",
        "Asking a question without providing any examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UK27S0E4_T1"
      },
      "source": [
        "print(\"=== Zero-Shot Prompting ===\\n\")\n",
        "prompt = \"What is prompt engineering? Explain in one sentence.\"\n",
        "result = get_completion(prompt, temp=0.3)\n",
        "print(f\"Prompt: {prompt}\\n\")\n",
        "print(f\"Output: {result}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrsFAYpa4_T3"
      },
      "source": [
        "### 2. Few-Shot Prompting\n",
        "Providing demonstrations to guide the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4l8qNQ-4_T3"
      },
      "source": [
        "print(\"\\n=== Few-Shot Prompting ===\\n\")\n",
        "prompt = \"\"\"Classify the sentiment as Positive or Negative:\n",
        "\n",
        "This is awesome! // Positive\n",
        "This is bad! // Negative\n",
        "Wow that movie was rad! // Positive\n",
        "What a horrible show! //\"\"\"\n",
        "\n",
        "result = get_completion(prompt, temp=0.2)\n",
        "print(f\"Prompt with examples:\\n{prompt}\\n\")\n",
        "print(f\"Output: {result}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd_YCJfD4_T4"
      },
      "source": [
        "### 3. Instruction Prompting\n",
        "Providing specific constraints and formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUU61Crq4_T4"
      },
      "source": [
        "print(\"\\n=== Instruction Prompting ===\\n\")\n",
        "prompt = \"\"\"Extract the names of places from the text below.\n",
        "Format: Place: <comma_separated_list>\n",
        "\n",
        "Text: 'at the Champalimaud Centre in Lisbon.'\"\"\"\n",
        "\n",
        "result = get_completion(prompt, temp=0.2)\n",
        "print(f\"Prompt: {prompt}\\n\")\n",
        "print(f\"Output: {result}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5A_aQiW4_T6"
      },
      "source": [
        "## Part 5 — Advanced Techniques\n",
        "\n",
        "### 1. Chain-of-Thought (CoT)\n",
        "Encourages step-by-step reasoning to solve logic traps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLPcq79_4_T6"
      },
      "source": [
        "print(\"=== Chain-of-Thought Prompting ===\\n\")\n",
        "\n",
        "# Without CoT\n",
        "prompt_direct = \"A juggler can juggle 16 balls. Half are golf balls, and half of the golf balls are blue. How many blue golf balls?\"\n",
        "print(\"Without CoT (Direct answer):\")\n",
        "result_direct = get_completion(prompt_direct, temp=0.2)\n",
        "print(f\"Q: {prompt_direct}\")\n",
        "print(f\"A: {result_direct}\\n\")\n",
        "\n",
        "# With CoT\n",
        "prompt_cot = \"A juggler can juggle 16 balls. Half are golf balls, and half of the golf balls are blue. How many blue golf balls? Let's think step by step.\"\n",
        "print(\"With CoT (Step-by-step reasoning):\")\n",
        "result_cot = get_completion(prompt_cot, temp=0.2)\n",
        "print(f\"Q: {prompt_cot}\")\n",
        "print(f\"A: {result_cot}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c4zWMxM4_T6"
      },
      "source": [
        "### 2. Program-Aided Language Models (PAL)\n",
        "Offloads math to a Python interpreter to ensure calculation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAI1hB-84_T7"
      },
      "source": [
        "print(\"\\n=== Program-Aided Language Models (PAL) ===\\n\")\n",
        "\n",
        "prompt_pal = \"\"\"The bakers baked 200 loaves. They sold 93 in the morning and 39 in the afternoon. 6 loaves were returned unsold. How many loaves are left?\n",
        "\n",
        "Let's solve this step by step with Python code:\"\"\"\n",
        "\n",
        "result_pal = get_completion(prompt_pal, temp=0.2, max_tokens=300)\n",
        "print(f\"Prompt: {prompt_pal}\\n\")\n",
        "print(f\"Output with code:\\n{result_pal}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awypspYY4_T7"
      },
      "source": [
        "### 3. ReAct (Reason + Act)\n",
        "Interleaves reasoning traces with tool-use actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUNRPnj14_T7"
      },
      "source": [
        "print(\"\\n=== ReAct Prompting (Reason + Act) ===\\n\")\n",
        "\n",
        "prompt_react = \"\"\"Answer the following question using the ReAct format:\n",
        "Question: What device can control the Front Row media center besides the original Apple Remote?\n",
        "\n",
        "Thought 1: I need to search for what the Apple Remote was originally designed for.\n",
        "Action 1: Search[Apple Remote original purpose]\n",
        "Observation 1: The Apple Remote was originally designed to control the Front Row media center on Mac computers.\n",
        "\n",
        "Thought 2: Now I need to find what other devices can control Front Row.\n",
        "Action 2: Search[devices compatible with Front Row]\n",
        "Observation 2: Front Row could also be controlled by some third-party universal remotes and iPhone apps with Wi-Fi remote capabilities.\n",
        "\n",
        "Thought 3: I have enough information to answer the question.\n",
        "Action 3: Finish[Third-party universal remotes and iPhone apps with Wi-Fi remote capabilities can control Front Row besides the original Apple Remote.]\n",
        "\n",
        "Now try this format with: What is the capital of France?\"\"\"\n",
        "\n",
        "result_react = get_completion(prompt_react, temp=0.3, max_tokens=400)\n",
        "print(result_react)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YblVwA4M4_T8"
      },
      "source": [
        "### 4. Generated Knowledge Prompting\n",
        "Generate facts first to improve commonsense reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jMKyAjq4_T8"
      },
      "source": [
        "print(\"\\n=== Generated Knowledge Prompting ===\\n\")\n",
        "\n",
        "prompt_knowledge = \"\"\"First, generate relevant facts about golf, then answer the question.\n",
        "\n",
        "Question: Is the statement true? 'Part of golf is trying to get a higher point total than others.'\n",
        "\n",
        "Step 1 - Generate facts about golf:\"\"\"\n",
        "result_knowledge = get_completion(prompt_knowledge, temp=0.4, max_tokens=400)\n",
        "print(result_knowledge)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg_RMgi74_T8"
      },
      "source": [
        "## Part 6 — Best Practices & Cheat Sheet\n",
        "\n",
        "### Key Principles\n",
        "\n",
        "| Principle | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| **Be Specific** | Use clear action words | \"Write a summary,\" \"Classify as,\" \"Extract dates\" |\n",
        "| **Focus on \"Do\"** | Tell what to do, not what not to do | ✅ \"Write in English\" vs ❌ \"Don't write in French\" |\n",
        "| **Use Separators** | Mark boundaries clearly | \"### Instructions ###\\nSummarize:\\n### Text ###\\n{text}\" |\n",
        "| **Iterate** | Start simple, add complexity gradually | Start with zero-shot → Add examples → Add constraints |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulncBMYl4_T9"
      },
      "source": [
        "print(\"=== Putting It All Together: Best Practices Demo ===\\n\")\n",
        "\n",
        "# Example of following best practices\n",
        "prompt_best = \"\"\"### TASK ###\n",
        "Summarize the following product review in 2-3 sentences, focusing only on pros and cons.\n",
        "\n",
        "### FORMAT ###\n",
        "Pros: <list pros>\n",
        "Cons: <list cons>\n",
        "Summary: <brief summary>\n",
        "\n",
        "### REVIEW ###\n",
        "I bought this wireless mouse last week. The battery life is amazing - been using it daily and still at 100%. It's very comfortable for my hand size. However, the Bluetooth connection sometimes drops randomly, especially when my laptop is more than 3 feet away. The silent clicks are great for working in libraries, but the scroll wheel feels a bit loose. Customer support was responsive when I emailed them about the connection issues.\n",
        "\n",
        "### RESPONSE ###\"\"\"\n",
        "\n",
        "result_best = get_completion(prompt_best, temp=0.3)\n",
        "print(f\"Prompt following best practices:\\n{result_best}\")\n",
        "\n",
        "# Quick comparison: Poor vs Good prompting\n",
        "print(\"\\n=== Poor Prompting vs Good Prompting ===\\n\")\n",
        "\n",
        "poor_prompt = \"tell me about ai\"\n",
        "good_prompt = \"\"\"### INSTRUCTION ###\n",
        "Provide a comprehensive overview of Artificial Intelligence (AI) with:\n",
        "1. A simple definition (1 sentence)\n",
        "2. Three main types of AI\n",
        "3. Two real-world applications\n",
        "4. One current limitation\n",
        "\n",
        "Keep the total response under 150 words.\n",
        "### END ###\"\"\"\n",
        "\n",
        "print(\"Poor prompt: 'tell me about ai'\")\n",
        "print(\"Good prompt includes:\\n- Clear structure\\n- Specific requirements\\n- Format constraints\\n- Word limit\\n\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtQNm-w24_T9"
      },
      "source": [
        "## Practice Exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A39sKw0m4_T-"
      },
      "source": [
        "print(\"=== Practice Exercises ===\\n\")\n",
        "print(\"Try modifying the following exercises to test your skills:\\n\")\n",
        "\n",
        "exercises = [\n",
        "    \"1. Zero-shot: Ask the model to classify movie genres\",\n",
        "    \"2. Few-shot: Provide 3 examples of English to Spanish translations, then translate 'Hello, how are you?\",\n",
        "    \"3. Chain-of-Thought: Solve a multi-step math word problem\",\n",
        "    \"4. Instruction-based: Extract email addresses and phone numbers from a text\",\n",
        "    \"5. Format control: Generate a response in JSON format\"\n",
        "]\n",
        "\n",
        "for ex in exercises:\n",
        "    print(ex)\n",
        "\n",
        "print(\"\\nExample exercise to try:\")\n",
        "prompt_exercise = \"\"\"Translate these English phrases to French:\n",
        "\n",
        "Example 1: Good morning -> Bonjour\n",
        "Example 2: Thank you -> Merci\n",
        "Example 3: How much? -> Combien?\n",
        "\n",
        "Now translate: Where is the nearest restaurant?\"\"\"\n",
        "\n",
        "print(f\"\\nExercise prompt:\\n{prompt_exercise}\")\n",
        "print(\"\\nRun this cell to see the result:\")\n",
        "# Uncomment to test:\n",
        "# result_exercise = get_completion(prompt_exercise, temp=0.3)\n",
        "# print(result_exercise)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZB7BP4W4_T_"
      },
      "source": [
        "## Summary & Key Takeaways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFnsKjrR4_T_"
      },
      "source": [
        "print(\"\"\"\n",
        "╔════════════════════════════════════════════════════════════╗\n",
        "║                 PROMPT ENGINEERING CHEAT SHEET             ║\n",
        "╠════════════════════════════════════════════════════════════╣\n",
        "║                                                            ║\n",
        "║   Start Simple → Iterate & Refine                          ║\n",
        "║   Be Specific & Clear                                      ║\n",
        "║   Adjust Parameters Strategically                          ║\n",
        "║   Use Examples for Complex Tasks                           ║\n",
        "║   Offload Computation When Needed                          ║\n",
        "║   Think Step-by-Step for Reasoning                         ║\n",
        "║                                                            ║\n",
        "║  Remember:                                                 ║\n",
        "║  • Temperature = Creativity                                ║\n",
        "║  • Top-P = Word Choice Range                               ║\n",
        "║  • Max Tokens = Response Length                            ║\n",
        "║  • Stop Sequences = Control Points                         ║\n",
        "║                                                            ║\n",
        "╚════════════════════════════════════════════════════════════╝\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"**Next Steps:**\")\n",
        "print(\"1. Practice with different prompts\")\n",
        "print(\"2. Experiment with parameters\")\n",
        "print(\"3. Try combining techniques\")\n",
        "print(\"4. Build your own prompt templates\")\n",
        "print(\"5. Explore more advanced topics like Auto-CoT and Tree of Thoughts\")"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
